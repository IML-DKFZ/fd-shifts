# @package _global_


trainer:
  num_epochs: 200 # 250 has to be >1 because of incompatibility of lighting eval with psuedo test
  val_every_n_epoch: 1 #has to be 1 because of schedulers
  val_split: "devries"  # leave empty for no val
  batch_size: 128
  resume_from_ckpt: False
  benchmark: True # set to false if input size varies during training!
  fast_dev_run: False # True/Fals
  lr_scheduler:
    name: "CosineAnnealing" # "MultiStep" "CosineAnnealing"
    milestones: [60, 120, 160] # lighting only steps schedulre during validation. so milestones need to be divisible by val_every_n_epoch
    max_epochs: ${trainer.num_epochs}
  optimizer:
    name: SGD
    learning_rate: 1e-1
    momentum: 0.9
    nesterov: True
    weight_decay: 0.0005
  callbacks:
    model_checkpoint:
      n: 1
      selection_metric: ["val/accuracy"] # in logging syntax: val/loss, makes ure to self.log() this metric! Set to empty to disable. also dont forget confid_prefix.
      mode: ["max"]
      filename: ["best_valacc"]# min:lower is better, max: higher is better
      save_top_k: [1]
    confid_monitor:   # not nice: model_checkpoint callback depends on confid_mointor callback
    learning_rate_monitor:

#model:
#  name: devries_model #det_mcd_model
#  fc_dim: 512
#  budget: 0.3
#  dropout_flag: True
#  network:
#    name: devries_and_enc      # confidnet_small_conv_and_enc / small_conv
#    backbone: vgg16
#    imagenet_weights_path: # ${env:EXPERIMENT_ROOT_DIR}/pretrained_weights/vgg16-397923af.pth

model:
  name: devries_model #det_mcd_model
  fc_dim: 512
  confidnet_fc_dim: 400
  avg_pool: True
  dropout_rate: 0 # 0 sets dropout to false
  monitor_mcd_samples: 50 # only activated if "mcd" substring in train or val monitor confids.
  test_mcd_samples: 50 # only activated if "mcd" substring in test confids.
  budget: 0.3
  network:
    name: devries_and_enc      # confidnet_small_conv_and_enc / small_conv
    backbone: vgg13
    imagenet_weights_path: # ${env:EXPERIMENT_ROOT_DIR}/pretrained_weights/vgg16-397923af.pth


test:
  name: test_results
  dir: ${exp.dir}/${test.name}
  cf_path: ${exp.dir}/hydra/config.yaml
  selection_criterion: "latest" #"best_valacc" #best_valacc # model selection criterion or "latest"
#  selection_mode: "l#max # model selection criterion or "latest"
  best_ckpt_path: ${exp.version_dir}/${test.selection_criterion}.ckpt # latest or best
  only_latest_version: True # if false looks for best metrics across all versions in exp_dir. Turn to false if resumed training.
  devries_repro_ood_split: True
  assim_ood_norm_flag: False
  iid_set_split: "devries"  # all, devries


eval:
  performance_metrics:
    train: ['loss', 'nll', 'accuracy'] # train brier_score logging costs around 5% performance
    val: ['loss', 'nll', 'accuracy', 'brier_score']
    test: ['nll', 'accuracy', 'brier_score']
  confid_metrics:
    train: ['failauc', 'failap_suc', 'failap_err', "fpr@95tpr"]
    val: ['failauc', 'failap_suc', 'failap_err', "fpr@95tpr",  "e-aurc", "aurc"]
    test: ['failauc', 'failap_suc', 'failap_err', "mce", "ece", "e-aurc", "aurc", "fpr@95tpr"]
  confidence_measures: # ["det_mcp" , "det_pe", "tcp" , "mcd_mcp", "mcd_pe", "mcd_ee", "mcd_mi", "mcd_sv"]
    train:
      ["det_mcp"] # mcd_confs not available due to performance. 'det_mcp' costs around 3% (hard to say more volatile)
    val:
      ["det_mcp"] # , "mcd_mcp", "mcd_pe", "mcd_ee", "mcd_mi", "mcd_sv"
    test:
      ["det_mcp" , "det_pe", "ext"]

  monitor_plots: [ #"calibration",
                   #"overconfidence",
                   "hist_per_confid"
                    ]

  tb_hparams: ['fold']
  ext_confid_name: "devries"
  test_conf_scaling: False
  val_tuning: False

  query_studies: # iid_study, new_class_study, sub_class_study, noise_study
    iid_study: cifar10
    new_class_study:
      - tinyimagenet
      - tinyimagenet_resize
      - cifar100
      - svhn

