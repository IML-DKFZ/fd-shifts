# @package _global_
exp:
  group_name: lidc_idri_prototyping
  name: lidc_idri_confidnet
trainer:
  num_epochs: 65
  num_epochs_backbone: 45
  val_every_n_epoch: 1
  # val splits:
  # - null: no validation set is created
  # - "devries": split the first 1000 cases of the iid test set as validation set
  # - cv: split 10% of the training set as validation set
  # - repro_confidnet: use the same cv split as Corbiere et al. 2020 (ConfidNet)
  val_split: "tenPercent"
  do_val: True
  accelerator: None
  
  learning_rate: 0.00015
  optimizer:
    name: ADAM
    learning_rate: 0.00015
    momentum: 0
    nesterov: False
    weight_decay: 0.1
  learning_rate_confidnet: 1e-4
  learning_rate_confidnet_finetune: 1e-6
  lr_scheduler:
    name: "CosineAnnealing" # "MultiStep" "CosineAnnealing"
    gamma: 0.1
    milestones: [100, 110] 
    max_epochs: ${trainer.num_epochs}
  momentum: 0
  weight_decay: 0.1
  batch_size: 512
  resume_from_ckpt: False
  benchmark: True # set to false if input size varies during training!
  fast_dev_run: False # True/Fals
  callbacks:
    model_checkpoint:
    confid_monitor:
    learning_rate_monitor:
    training_stages:
      milestones: [45, 55]
      pretrained_backbone_path: #/mnt/hdd2/checkpoints/checks/check_global_traintest/version_29/best_valacc.ckpt #  /mnt/hdd2/checkpoints/svhn_smallconv/model_epoch_076.ckpt # leave empty to train backbone on the fly. If set, first milestone needs to be 0!
      pretrained_confidnet_path: #/mnt/hdd2/checkpoints/checks/check_pretrained_confidnet/version_43/best_failap_err.ckpt # leave empty to train confidnet on the fly. If set, second milestone needs to be 0!
      disable_dropout_at_finetuning: True
      confidnet_lr_scheduler: False
model:
  name: confidnet_model_mod #det_mcd_model
  fc_dim: 1024
  dg_reward: 2.2 # dummy
  avg_pool: True
  dropout_rate: 0
  confidnet_fc_dim: 400
  monitor_mcd_samples: 10 # only activated if "mcd" substring in train or val monitor confids.
  test_mcd_samples: 10 # only activated if "mcd" substring in test confids.
  budget: 0.3
  network: 
    name: confidnet_and_enc #devries_and_enc      # confidnet_small_conv_and_enc / small_conv
    backbone: densenet121
    imagenet_weights_path: # ${env:EXPERIMENT_ROOT_DIR}/pretrained_weights/vgg16-397923af.pth
    load_dg_backbone_path: #${exp.dir}/dg_backbone_2.ckpt  # ${env:EXPERIMENT_ROOT_DIR}/pretrained_weights/vgg16-397923af.pth
    save_dg_backbone_path:

test:
  name: test_results
  dir: ${exp.dir}/${test.name}
  cf_path: ${exp.dir}/hydra/config.yaml
  selection_criterion: latest # latest / best_failap_err
  selection_mode: #"latest" # model selection criterion or "latest"
  best_ckpt_path: ${exp.version_dir}/${test.selection_criterion}.ckpt # latest or best
  only_latest_version: True # if false looks for best metrics across all versions in exp_dir. Turn to false if resumed training.
  devries_repro_ood_split: False
  assim_ood_norm_flag: False
  iid_set_split: "tenPercent"  # all, devries

eval:
  performance_metrics:
    train: ["loss", "nll", "accuracy"] # train brier_score logging costs around 5% performance
    val: ["loss", "nll", "accuracy", "brier_score"]
    test: ["nll", "accuracy", "brier_score"]
  confid_metrics:
    train:
      ["failauc", "failap_suc", "failap_err", "fpr@95tpr", "e-aurc", "aurc"]
    val: ["failauc", "failap_suc", "failap_err", "fpr@95tpr", "e-aurc", "aurc"]
    test:
      [
        "failauc",
        "failap_suc",
        "failap_err",
        "mce",
        "ece",
        "e-aurc",
        "aurc",
        "fpr@95tpr",
      ]
  confidence_measures: # ["det_mcp" , "det_pe", "tcp" , "mcd_mcp", "mcd_pe", "mcd_ee", "mcd_mi", "mcd_sv"]
    train: ["det_mcp"] # mcd_confs not available due to performance. 'det_mcp' costs around 3% (hard to say more volatile)
    val: ["det_mcp"] # , "mcd_mcp", "mcd_pe", "mcd_ee", "mcd_mi", "mcd_sv"
    test:
      ["det_mcp", "det_pe", "ext", "mcd_mcp", "mcd_pe", "mcd_ee"]

  monitor_plots: #"calibration",
    [
      #"overconfidence",
      "hist_per_confid",
    ]

  tb_hparams: ["fold"]
  val_tuning: True
  ext_confid_name: "tcp"
  test_conf_scaling: False
  r_star: 0.25
  r_delta: 0.05

  query_studies: # iid_study, new_class_study, sub_class_study, noise_study
   iid_study: ${data.dataset}
   in_class_study:
