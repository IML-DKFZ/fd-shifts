# @package _global_
defaults:
  - override /data: isic_v01_cr_data

exp:
  group_name: isic
  name: isic_name

trainer:
  num_epochs: 30
  num_steps: 
  max_epochs: 15
  val_every_n_epoch: 1
  accumulate_grad_batches: 1
  accelerator: 
  do_val: False
  val_split: devries
  learning_rate: 0.00003
  lr_scheduler:
    name: "CosineAnnealingWarmRestarts" # "MultiStep" "CosineAnnealing"
    warmup_epochs: 1
    warmup_start_lr: 0
    eta_min: 0
    max_epochs: 15
  optimizer:
    name: "ADAM"
  momentum: 0.9
  weight_decay: 0.0
  batch_size: 64
  resume_from_ckpt: False
  benchmark: True # set to false if input size varies during training!
  fast_dev_run: False # True/Fals
  callbacks:
    model_checkpoint:
    confid_monitor: # not nice: model_checkpoint callback depends on confid_mointor callback
    learning_rate_monitor:

model:
  name: isic_model
  dropout_rate: 1
  network:
    name: efficientnetb4

test:
  name: test_results
  dir: ${exp.dir}/${test.name}
  cf_path: ${exp.dir}/hydra/config.yaml
  raw_output_path: ${test.dir}/raw_output.npy
  external_confids_output_path: ${test.dir}/external_confids.npy
  selection_criterion: latest # model selection criterion or "latest"
  selection_mode: max # model selection criterion or "latest"
  best_ckpt_path: ${exp.version_dir}/${test.selection_criterion}.ckpt # latest or best
  only_latest_version: True # if false looks for best metrics across all versions in exp_dir. Turn to false if resumed training.
  devries_repro_ood_split: False
  assim_ood_norm_flag: False
  iid_set_split: "all" # all, devries

eval:
  performance_metrics:
    train: ["loss", "nll", "accuracy"] # train brier_score logging costs around 5% performance
    val: ["loss", "nll", "accuracy", "brier_score"]
    test: ["nll", "accuracy", "brier_score"]
  confid_metrics:
    train: ["failauc", "failap_suc", "failap_err", "fpr@95tpr"]
    val: ["failauc", "failap_suc", "failap_err", "fpr@95tpr", "e-aurc", "aurc"]
    test:
      [
        "failauc",
        "failap_suc",
        "failap_err",
        "mce",
        "ece",
        "e-aurc",
        "aurc",
        "fpr@95tpr",
      ]
  confidence_measures: # ["det_mcp" , "det_pe", "tcp" , "mcd_mcp", "mcd_pe", "mcd_ee", "mcd_mi", "mcd_sv"]
    train: ["det_mcp"] # mcd_confs not available due to performance. 'det_mcp' costs around 3% (hard to say more volatile)
    val: ["det_mcp"] # , "mcd_mcp", "mcd_pe", "mcd_ee", "mcd_mi", "mcd_sv"
    test: ["det_mcp", "det_pe"]

  monitor_plots: #"calibration",
    [
      #"overconfidence",
      "hist_per_confid",
    ]
  val_tuning: False
  r_star: 0.25
  r_delta: 0.05
  tb_hparams: ["fold"]
  ext_confid_name: "maha"

  query_studies: # iid_study, new_class_study, sub_class_study, noise_study
   iid_study: ${data.dataset}
   in_class_study: [dermoscopyalld7p]

