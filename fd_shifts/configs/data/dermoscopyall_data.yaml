# @package _global_
defaults:
  - override /trainer/lr_scheduler: CosineAnnealingLR
  - override /trainer/optimizer: Adam

data:
  dataset: dermoscopyall
  data_dir: ${oc.env:DATASET_ROOT_DIR}/${data.dataset}
  pin_memory: True
  img_size: [512, 512, 3] #dataset is 28x28x1 either upscale it or need to adjust transforms and neural net
  num_workers: 12
  num_classes: 2
  reproduce_confidnet_splits: True
  target_transforms:
    train:
      extractZeroDim:
    val:
      extractZeroDim:
    test:
      extractZeroDim:  

  augmentations:
    train: # careful, the order here will determine the order of transforms (except normalize will be executed manually at the end after toTensor)

    val:
      
    test:

      

  kwargs:
    
eval:
  query_studies:
    iid_study: ${data.dataset}

trainer:
  batch_size: 16
  # num_epochs: 30
  num_epochs: ${fd_shifts.ifeq_else:${eval.ext_confid_name},tcp,30,${fd_shifts.ifeq_else:${eval.ext_confid_name},dg,20,15}}
  optimizer:
    lr: 3e-5
    weight_decay: 0
    # nesterov: True
  num_epochs_backbone: 20
  dg_pretrain_epochs: 15
  val_every_n_epoch: 5

model:
  fc_dim: 1792
  network:
    backbone: efficientnetb4
