# @package _global_

data:
  dataset: cifar10
  data_dir: ${oc.env:DATASET_ROOT_DIR}/${data.dataset}
  pin_memory: True
  img_size: [32, 32, 3]
  num_workers: 12
  num_classes: 10
  reproduce_confidnet_splits: True
  augmentations:
    train: # careful, the order here will determine the order of transforms (except normalize will be executed manually at the end after toTensor)
      random_crop: [32, 4] # size, padding
      hflip: True
      #      rotate: 15
      to_tensor:
      normalize: [[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]
      cutout: 16
    val:
      to_tensor:
      normalize: [[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]
    test:
      to_tensor:
      normalize: [[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]]

  #      standard values: [ [ 0.4914, 0.4822, 0.4465 ], [ 0.2023, 0.1994, 0.2010 ] ]
  #  tiny imagenet values: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]
  # dvries values: [[0.4913725490196078, 0.4823529411764706, 0.4466666666666667], [0.24705882352941178, 0.24352941176470588, 0.2615686274509804]]

  kwargs:

eval:
  query_studies:
    iid_study: cifar10
    noise_study:
      - corrupt_cifar10
    new_class_study:
      - cifar100
      - svhn
      - tinyimagenet_resize

trainer:
  batch_size: 128
  num_epochs: ${fd_shifts.ifeq_else:${eval.ext_confid_name},tcp,470,${fd_shifts.ifeq_else:${eval.ext_confid_name},dg,300,250}}
  num_epochs_backbone: 250
  dg_pretrain_epochs: 100
  optimizer:
    lr: 1e-1
    weight_decay: 5e-4
