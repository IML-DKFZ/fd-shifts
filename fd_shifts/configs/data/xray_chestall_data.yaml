# @package _global_
defaults:
  - override /trainer/lr_scheduler: CosineAnnealingLR
  - override /trainer/optimizer: Adam

data:
  dataset: xray_chestall
  data_dir: ${oc.env:DATASET_ROOT_DIR}/${data.dataset}
  pin_memory: True
  img_size: [256, 256, 3] #dataset is 28x28x1 either upscale it or need to adjust transforms and neural net
  num_workers: 24
  num_classes: 8
  reproduce_confidnet_splits: True
  target_transforms:
    train:
      extractZeroDim:
    val:
      extractZeroDim:
    test:
      extractZeroDim:  

  augmentations:
    train: # careful, the order here will determine the order of transforms (except normalize will be executed manually at the end after toTensor)
      to_tensor:
      hflip: 1
      rotate: 15
      resize: 256
      center_crop: 256
      normalize: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]
    val:
      to_tensor:
      resize: 256
      center_crop: 256
      normalize: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]    
    test:
      to_tensor:
      resize: 256
      center_crop: 256
      normalize: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]
      

  kwargs:
    
eval:
  performance_metrics:
    test:
      - nll
      - accuracy
      - brier_score
      # - b-accuracy
  query_studies:
    iid_study: ${data.dataset}

trainer:
  batch_size: 96
  num_epochs: ${fd_shifts.ifeq_else:${eval.ext_confid_name},tcp,60,${fd_shifts.ifeq_else:${eval.ext_confid_name},dg,40,30}}
  optimizer:
    lr: 3e-5
    weight_decay: 1e-4
    # nesterov: False
    # momentum: 0.9
  num_epochs_backbone: 30
  dg_pretrain_epochs: 30
  val_every_n_epoch: 5

model:
  fc_dim: 1024
  network:
    backbone: densenet121
