{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "meanprops = dict(linestyle=\"-\", linewidth=6, color=\"k\", alpha=1, zorder=99)\n",
    "whiskerprops = dict(linestyle=\"-\", linewidth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_names = [\n",
    "    \"svhn\",\n",
    "    \"cifar10\",\n",
    "    \"cifar100\",\n",
    "    \"super_cifar100\",\n",
    "    \"camelyon\",\n",
    "    \"animals\",\n",
    "    \"breeds\",\n",
    "    \"svhnvit\",\n",
    "    \"cifar10vit\",\n",
    "    \"cifar100vit\",\n",
    "    \"super_cifar100vit\",\n",
    "    \"camelyonvit\",\n",
    "    \"animalsvit\",\n",
    "    \"breedsvit\",\n",
    "]\n",
    "\n",
    "df_list = []\n",
    "for exp in exp_names:\n",
    "    # in_path = os.path.join(\"/Users/Paul/research/files/analysis/csvs/{}_paper_sweep.csv\".format(exp))\n",
    "    in_path = os.path.join(\n",
    "        \"/home/tillb/Projects/failure-detection-benchmark/results/{}.csv\".format(exp)\n",
    "    )\n",
    "    df = pd.read_csv(in_path)\n",
    "    df = df.dropna(subset=[\"name\", \"model\"])\n",
    "    df = df.drop_duplicates(subset=[\"name\", \"study\", \"model\", \"network\", \"confid\"])\n",
    "    df = df[\n",
    "        (~df.study.str.contains(\"tinyimagenet_original\"))\n",
    "        & (~df.study.str.contains(\"tinyimagenet_proposed\"))\n",
    "    ]\n",
    "    if exp == \"cifar10\" or exp == \"cifar100\" or exp == \"super_cifar100\":\n",
    "        df = df[(df.name.str.contains(\"vgg13\"))]\n",
    "    if exp == \"super_cifar100\":\n",
    "        df = df[df.study == \"iid_study\"]\n",
    "        df[\"study\"] = df.apply(\n",
    "            lambda row: \"cifar100_in_class_study_superclasses\", axis=1\n",
    "        )\n",
    "    elif exp == \"super_cifar100vit\":\n",
    "        df = df[(df.study == \"iid_study\") & (~(df.old_name.str.contains(\"modeldevries\")))]  # TODO: DG/Devries/Confidnet for cifar100 not run yet\n",
    "        df[\"study\"] = df.apply(\n",
    "            lambda row: \"cifar100vit_in_class_study_superclasses\", axis=1\n",
    "        )\n",
    "    else:\n",
    "        df[\"study\"] = df.apply(lambda row: exp + \"_\" + row[\"study\"], axis=1)\n",
    "    print(exp, len(df.groupby(\"name\").count()))\n",
    "\n",
    "    df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "exp_names = [e for e in exp_names if not e.startswith(\"super_cifar100\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\n",
    "    (df.name.str.contains(\"dg_bbvgg13_do1\"))\n",
    "    & (df.study == \"cifar100_iid_study\")\n",
    "    & (df.confid == \"dg_mcd_mcp\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(\"study\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"backbone\"] = df.apply(lambda row: row[\"name\"].split(\"bb\")[1].split(\"_\")[0], axis=1)\n",
    "df[\"dropout\"] = df.apply(lambda row: row[\"name\"].split(\"do\")[1].split(\"_\")[0], axis=1)\n",
    "df[\"model\"] = df.apply(lambda row: row[\"name\"].split(\"_\")[0], axis=1)\n",
    "df[\"model\"] = df.apply(lambda row: \"vit_\" + row[\"name\"].split(\"model\")[1].split(\"_\")[0] if (row[\"model\"] == \"vit\" and \"model\" in row[\"name\"]) else row[\"model\"], axis=1)\n",
    "df[\"run\"] = df.apply(lambda row: row[\"name\"].split(\"run\")[1].split(\"_\")[0], axis=1)\n",
    "df[\"rew\"] = df.apply(lambda row: row[\"name\"].split(\"_rew\")[1].split(\"_\")[0], axis=1)\n",
    "df[\"confid\"] = df.apply(\n",
    "    lambda row: row[\"model\"]\n",
    "    + \"_\"\n",
    "    + row[\"confid\"]\n",
    "    + \"_\"\n",
    "    + row[\"dropout\"]\n",
    "    + \"_\"\n",
    "    + row[\"rew\"],\n",
    "    axis=1,\n",
    ")\n",
    "df = df.drop(\"model\", axis=1)\n",
    "df = df.drop(\"dropout\", axis=1)\n",
    "\n",
    "\n",
    "df = df.drop(\"backbone\", axis=1)\n",
    "print(len(df))\n",
    "# print(df[df.study.str.contains(\"cifar100vit\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MODEL SELECTION\n",
    "\n",
    "\n",
    "def select_func(row, selection_df, selection_column):\n",
    "    name_splitter = -1 if selection_column == \"rew\" else -2\n",
    "    row_exp = row[\"study\"].split(\"_\")[0] + \"_\"\n",
    "    row_confid = \"_\".join(row[\"confid\"].split(\"_\")[:name_splitter])\n",
    "    selection_df = selection_df[\n",
    "        (selection_df.study.str.contains(row_exp)) & (selection_df.confid == row_confid)\n",
    "    ]\n",
    "    try:\n",
    "        if row[selection_column] == selection_df[selection_column].tolist()[0]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except IndexError as e:\n",
    "        print(row_exp, row_confid, len(selection_df))\n",
    "        raise e\n",
    "\n",
    "\n",
    "ms_metric = \"aurc\"  # Careful, when changing consider changing idxmin -> idxmax\n",
    "\n",
    "# REWARD\n",
    "non_agg_columns = [\"study\", \"confid\", \"rew\"]\n",
    "ms_filter_metrics_df = df[[\"study\", \"confid\", \"run\", \"rew\", ms_metric]]\n",
    "df_ms = ms_filter_metrics_df.groupby(by=non_agg_columns).mean().reset_index()\n",
    "print(len(df_ms), len(ms_filter_metrics_df))\n",
    "df_ms = df_ms[df_ms.study.str.contains(\"val_tuning\")]\n",
    "df_ms[\"confid\"] = df_ms.apply(\n",
    "    lambda row: \"_\".join(row[\"confid\"].split(\"_\")[:-1]), axis=1\n",
    ")\n",
    "df_ms = df_ms.loc[\n",
    "    df_ms.groupby([\"study\", \"confid\"])[ms_metric].idxmin().reset_index()[ms_metric]\n",
    "]\n",
    "print(len(df), len(df_ms))\n",
    "df[\"select_rew\"] = df.apply(lambda row: select_func(row, df_ms, \"rew\"), axis=1)\n",
    "selected_df = df[df.select_rew == 1]\n",
    "\n",
    "# DROPOUT\n",
    "non_agg_columns = [\"study\", \"confid\", \"dropout\"]\n",
    "selected_df[\"dropout\"] = selected_df.apply(\n",
    "    lambda row: row[\"name\"].split(\"do\")[1].split(\"_\")[0], axis=1\n",
    ")\n",
    "do_filter_metrics_df = selected_df[[\"study\", \"confid\", \"run\", \"dropout\", ms_metric]]\n",
    "df_do = do_filter_metrics_df.groupby(by=non_agg_columns).mean().reset_index()\n",
    "print(len(df_do), len(do_filter_metrics_df))\n",
    "df_do = df_do[df_do.study.str.contains(\"val_tuning\")]\n",
    "df_do[\"confid\"] = df_do.apply(\n",
    "    lambda row: \"_\".join(row[\"confid\"].split(\"_\")[:-2]), axis=1\n",
    ")\n",
    "df_do = df_do.loc[\n",
    "    df_do.groupby([\"study\", \"confid\"])[ms_metric].idxmin().reset_index()[ms_metric]\n",
    "]\n",
    "print(len(df), len(selected_df), len(df_do))\n",
    "selected_df[\"select_do\"] = selected_df.apply(\n",
    "    lambda row: select_func(row, df_do, \"dropout\"), axis=1\n",
    ")\n",
    "all_selected_df = selected_df[selected_df.select_do == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "print(len(df), len(selected_df), len(all_selected_df), type)\n",
    "all_selected_df[\n",
    "    (all_selected_df.study.str.contains(\"val_tuning\")) & (all_selected_df.run == \"1\")\n",
    "][[\"study\", \"confid\", \"rew\", \"dropout\", \"aurc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rename_confids(in_confid):\n",
    "    confid = in_confid.replace(\"confidnet_\", \"\")\n",
    "    confid = confid.replace(\"_dg\", \"_res\")\n",
    "    # confid = confid.replace(\"dg_\", \"deepgamblers_\")\n",
    "    confid = confid.replace(\"_det\", \"\")\n",
    "    confid = confid.replace(\"det_\", \"\")\n",
    "#     confid = confid.replace(\"_devries\", \"\")\n",
    "    confid = confid.replace(\"tcp\", \"confidnet\")\n",
    "    confid = confid.upper()\n",
    "    confid = confid.replace(\"DEVRIES_DEVRIES\", \"DEVRIES\")\n",
    "    confid = confid.replace(\"VIT_VIT\", \"VIT\")\n",
    "    confid = confid.replace(\"DEVRIES\", \"Devries et al.\")\n",
    "    confid = confid.replace(\"CONFIDNET\", \"ConfidNet\")\n",
    "    confid = confid.replace(\"RES\", \"Res\")\n",
    "    confid = confid.replace(\"_\", \"-\")\n",
    "    confid = confid.replace(\"MCP\", \"MSR\")\n",
    "    confid = confid.replace(\"VIT-Res\", \"VIT-DG-Res\")\n",
    "    return confid\n",
    "\n",
    "\n",
    "# FINAL CLEANING AND ASSIGNING OF DF\n",
    "clean_df = all_selected_df.drop(\"dropout\", axis=1)\n",
    "\n",
    "# clean_df = clean_df.drop(\"rew\", axis=1)\n",
    "clean_df = clean_df[~clean_df.confid.str.contains(\"waic\")]\n",
    "clean_df[\"confid\"] = clean_df.apply(\n",
    "    lambda row: \"_\".join(row[\"confid\"].split(\"_\")[:-2]), axis=1\n",
    ")\n",
    "clean_df = clean_df[~clean_df.confid.str.contains(\"devries_mcd\")]\n",
    "clean_df = clean_df[~clean_df.confid.str.contains(\"devries_det\")]\n",
    "clean_df = clean_df[~clean_df.confid.str.contains(\"_sv\")]\n",
    "clean_df = clean_df[~clean_df.confid.str.contains(\"_mi\")]\n",
    "clean_df[\"confid\"][clean_df[\"network\"] == \"vit\"] = clean_df[\"confid\"][\n",
    "    clean_df[\"network\"] == \"vit\"\n",
    "].apply(lambda row: \"vit_\" + row)\n",
    "print(clean_df.confid.unique())\n",
    "clean_df[\"confid\"] = clean_df.apply(lambda row: rename_confids(row[\"confid\"]), axis=1)\n",
    "clean_df[\"study\"] = clean_df.study.str.replace(\n",
    "    \"tinyimagenet_384\", \"tinyimagenet_resize\"\n",
    ")\n",
    "clean_df[\"study\"] = clean_df.study.str.replace(\"vit\", \"\").str.replace(\"_384\", \"\")\n",
    "df = clean_df\n",
    "print(df.confid.unique())\n",
    "print(df.study.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Agregate over runs. Number TABLES. TODO GET RID OF REWARD FOR PROPER RANKING ACROSS STUDIES!\n",
    "\n",
    "metric = \"aurc\"\n",
    "non_agg_columns = [\"study\", \"confid\"]  # might need rew if no model selection\n",
    "filter_metrics_df = df[non_agg_columns + [\"run\", metric]]\n",
    "df_mean = filter_metrics_df.groupby(by=non_agg_columns).mean().reset_index().round(2)\n",
    "df_std = filter_metrics_df.groupby(by=non_agg_columns).std().reset_index().round(2)\n",
    "\n",
    "studies = df_mean.study.unique().tolist()\n",
    "dff = pd.DataFrame({\"confid\": df.confid.unique()})\n",
    "print(dff)\n",
    "print(\"CHECK LEN DFF\", len(dff), len(df_mean))\n",
    "combine_and_str = False\n",
    "if combine_and_str:\n",
    "    agg_mean_std = (\n",
    "        lambda s1, s2: s1\n",
    "        if (s1.name == \"confid\" or s1.name == \"study\" or s1.name == \"rew\")\n",
    "        else s1.astype(str) + \" ± \" + s2.astype(str)\n",
    "    )\n",
    "    df_mean = df_mean.combine(df_std, agg_mean_std)\n",
    "    for s in studies:\n",
    "        sdf = df_mean[df_mean.study == s]\n",
    "        dff[s] = dff[\"confid\"].map(sdf.set_index(\"confid\")[metric])\n",
    "\n",
    "\n",
    "else:\n",
    "    for s in studies:\n",
    "        sdf = df_mean[df_mean.study == s]\n",
    "        dff[s] = dff[\"confid\"].map(sdf.set_index(\"confid\")[metric])\n",
    "        # print(\"DFF\", dff.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tripple results\n",
    "\n",
    "non_agg_columns = [\"study\", \"confid\"]  # might need rew if no model selection\n",
    "filter_metrics_df = df[non_agg_columns + [\"run\", metric]]\n",
    "df_aurc = (\n",
    "    df[non_agg_columns + [\"run\", \"aurc\"]]\n",
    "    .groupby(by=non_agg_columns)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    ")\n",
    "df_auc = (\n",
    "    df[non_agg_columns + [\"run\", \"failauc\"]]\n",
    "    .groupby(by=non_agg_columns)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "df_acc = (\n",
    "    df[non_agg_columns + [\"run\", \"accuracy\"]]\n",
    "    .groupby(by=non_agg_columns)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "df_acc[\"aurc\"] = df_acc[\"accuracy\"] * 100\n",
    "df_acc = df_acc.round(2)\n",
    "df_auc[\"aurc\"] = df_auc[\"failauc\"] * 100\n",
    "df_auc = df_auc.round(2)\n",
    "studies = df_aurc.study.unique().tolist()\n",
    "tripple_dff = df_aurc[df_aurc.study == \"cifar100_iid_study\"][[\"confid\"]]\n",
    "print(\"CHECK LEN DFF\", len(dff), len(df_aurc))\n",
    "\n",
    "\n",
    "agg_mean_std = (\n",
    "    lambda s1, s2: s1\n",
    "    if (s1.name == \"confid\" or s1.name == \"study\" or s1.name == \"rew\")\n",
    "    else s1.astype(str) + \" / \" + s2.astype(str)\n",
    ")\n",
    "df_aurc = df_aurc.combine(df_acc, agg_mean_std)\n",
    "df_aurc = df_aurc.combine(df_auc, agg_mean_std)\n",
    "for s in studies:\n",
    "    sdf = df_aurc[df_aurc.study == s]\n",
    "    tripple_dff[s] = tripple_dff[\"confid\"].map(sdf.set_index(\"confid\")[\"aurc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PLOT METRICS SELECTION\n",
    "# df_acc\n",
    "plot_dff = dff[[\"confid\"] + [c for c in dff.columns if c.startswith(\"animals_\")]]\n",
    "columns = (\n",
    "    [\"confid\"]\n",
    "    + [c for c in plot_dff.columns if \"iid\" in c]\n",
    "    + [c for c in plot_dff.columns if \"ood\" in c]\n",
    "    + [c for c in plot_dff.columns if \"proposed\" in c]\n",
    ")\n",
    "print(columns, plot_dff.columns)\n",
    "# columns = [\"confid\"]+ [c for c in plot_dff.columns if \"noise\" in c]\n",
    "plot_dff[columns].set_index(\"confid\").to_latex(\n",
    "    \"/home/t974t/Projects/failure-detection-benchmark/results/animals\"\n",
    ")\n",
    "# print(len(df_aurc), len(df_auc), len(df_acc))\n",
    "# df_acc\n",
    "# dff[[\"confid\", \"dropout\"] + [c for c in dff.columns if \"original\" in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# RANKING DF\n",
    "\n",
    "# dff = dff[[\"confid\", \"rew\"] + [c for c in dff.columns if  c.startswith(\"cifar100\")]]\n",
    "select_df = dff\n",
    "rank_df = select_df.rank(na_option=\"keep\", numeric_only=True, ascending=False)\n",
    "# actually aurc should be ranked ascedingly, but we want the lowest rank to show on top on the y axis\n",
    "# so careful when using this df for other things than this plot!\n",
    "\n",
    "rank_df[\"confid\"] = dff.confid\n",
    "rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RANKING PLOTS\n",
    "\n",
    "scale = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt_exps = exp_names\n",
    "sns.set_context(\"paper\", font_scale=scale * 0.20)\n",
    "f, axs = plt.subplots(\n",
    "    nrows=len(plt_exps), ncols=1, figsize=(3 * scale, len(exp_names) * scale * 2)\n",
    ")\n",
    "# todo ! supercifar has to be a part of cifar100 exp. check also weird observation regarding val_tuning\n",
    "for ax_ix, exp in enumerate(plt_exps):\n",
    "    cols = [c for c in rank_df.columns if c.startswith(exp + \"_\")]\n",
    "    cols = (\n",
    "        [\"{}_val_tuning\".format(exp), \"{}_iid_study\".format(exp)]\n",
    "        + [c for c in cols if \"noise\" in c]\n",
    "        + [c for c in cols if \"in_class\" in c]\n",
    "        + [c for c in cols if \"proposed\" in c]\n",
    "    )\n",
    "    numeric_exp_df = rank_df[cols]\n",
    "    # todo DROPNAN?\n",
    "    confids_list = rank_df.confid.tolist()\n",
    "    x = range(len(numeric_exp_df.columns))\n",
    "    for ix in range(len(numeric_exp_df)):\n",
    "        y = numeric_exp_df.iloc[ix].values\n",
    "        axs[ax_ix].plot(x, y)\n",
    "    axs[ax_ix].set_yticks(range(1, len(numeric_exp_df) + 1))\n",
    "    axs[ax_ix].set_yticklabels(\n",
    "        rank_df[[\"confid\"] + [c for c in rank_df.columns if c.startswith(exp)]]\n",
    "        .sort_values(by=numeric_exp_df.columns[0])\n",
    "        .confid.tolist()\n",
    "    )\n",
    "    axs[ax_ix].set_xticks(x)\n",
    "    axs[ax_ix].set_xticklabels([c for c in numeric_exp_df.columns], rotation=90)\n",
    "    axs[ax_ix].set_xlim(0, len(numeric_exp_df.columns) - 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"green\",\n",
    "    \"tab:purple\",\n",
    "    \"orange\",\n",
    "    \"red\",\n",
    "    \"black\",\n",
    "    \"pink\",\n",
    "    \"olive\",\n",
    "    \"grey\",\n",
    "    \"brown\",\n",
    "    \"tab:cyan\",\n",
    "    \"blue\",\n",
    "    \"limegreen\",\n",
    "    \"darkmagenta\",\n",
    "    \"salmon\",\n",
    "    \"tab:blue\",\n",
    "    \"green\",\n",
    "    \"tab:purple\",\n",
    "    \"orange\",\n",
    "]\n",
    "print(len(rank_df.confid.str.replace(\"VIT-\", \"\").unique().tolist()))\n",
    "print(len(colors))\n",
    "\n",
    "color_dict = {conf: colors[ix] for ix, conf in enumerate(rank_df.confid.str.replace(\"VIT-\", \"\").unique().tolist())}\n",
    "color_dict.update({conf: color_dict[conf.replace(\"VIT-\", \"\")] for ix, conf in enumerate(rank_df.confid[rank_df.confid.str.contains(\"VIT\")].tolist())})\n",
    "print(color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SUM RANKING PLOTS\n",
    "\n",
    "select_columns = [c for c in rank_df.columns]\n",
    "iid_columns = [c for c in select_columns if \"iid\" in c]\n",
    "print(\"IID\", iid_columns)\n",
    "in_class_columns = [c for c in select_columns if \"in_class\" in c]\n",
    "print(\"SUB CLASS\", in_class_columns)\n",
    "new_class_columns = [\n",
    "    c for c in select_columns if (\"new_class\" in c and \"proposed\" in c)\n",
    "]\n",
    "sem_new_class_columns = [\n",
    "    c for c in new_class_columns if (\"cifar10_\" in c and \"cifar100_\" in c)\n",
    "]\n",
    "print(\"SEMANTIC NEW CLASS\", sem_new_class_columns)\n",
    "nonsem_new_class_columns = [\n",
    "    c for c in new_class_columns if c not in sem_new_class_columns\n",
    "]\n",
    "print(\"NON-SEMANTIC NEW CLASS\", nonsem_new_class_columns)\n",
    "noise_columns = [c for c in select_columns if \"noise\" in c]\n",
    "print(\"NOISE\", noise_columns)\n",
    "sum_rank_df = rank_df[[\"confid\"]]\n",
    "sum_rank_df[\"iid\"] = rank_df[iid_columns].sum(axis=1, numeric_only=True, skipna=False)\n",
    "sum_rank_df[\"corruption-shift\"] = rank_df[noise_columns].sum(\n",
    "    axis=1, numeric_only=True, skipna=False\n",
    ")\n",
    "if len(in_class_columns) > 0:\n",
    "    sum_rank_df[\"sub-class-shift\"] = rank_df[in_class_columns].sum(\n",
    "        axis=1, numeric_only=True, skipna=False\n",
    "    )\n",
    "sum_rank_df[\"sem.-new-class-shift\"] = rank_df[sem_new_class_columns].sum(\n",
    "    axis=1, numeric_only=True, skipna=False\n",
    ")\n",
    "sum_rank_df[\"non-sem.-new-class-shift\"] = rank_df[nonsem_new_class_columns].sum(\n",
    "    axis=1, numeric_only=True, skipna=False\n",
    ")\n",
    "sum_rank_df = sum_rank_df.rank(na_option=\"keep\", numeric_only=True, ascending=True)\n",
    "sum_rank_df[\"confid\"] = rank_df.confid\n",
    "sum_rank_df[\"aggregated\"] = sum_rank_df.sum(\n",
    "    axis=1, numeric_only=True, skipna=False\n",
    ").rank(na_option=\"keep\", ascending=True)\n",
    "\n",
    "# sum_rank_df[\"iid\"] = sum_rank_df.apply(lambda row: row[\"iid\"] + 0.5 if row[\"confid\"] == \"confidnet_mcd\" else row[\"iid\"], axis=1)\n",
    "# sum_rank_df[\"iid\"] = sum_rank_df.apply(lambda row: row[\"iid\"] - 0.5 if row[\"confid\"] == \"deepgamblers_mcd_mi\" else row[\"iid\"], axis=1)\n",
    "\n",
    "scale = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=scale * 0.50)\n",
    "f, axs = plt.subplots(nrows=1, ncols=1, figsize=(3 * scale, 1.5 * scale * 1.2))\n",
    "# todo ! supercifar has to be a part of cifar100 exp. check also weird observation regarding val_tuning\n",
    "\n",
    "show_columns = [\n",
    "    \"iid\",\n",
    "    \"corruption-shift\",\n",
    "    \"sub-class-shift\",\n",
    "    \"sem.-new-class-shift\",\n",
    "    \"non-sem.-new-class-shift\",\n",
    "    \"aggregated\",\n",
    "]\n",
    "cols = show_columns  # [c for c in sum_rank_df.columns if c.startswith(\"sum\")]\n",
    "numeric_exp_df = sum_rank_df[cols]\n",
    "print(numeric_exp_df)\n",
    "# todo DROPNAN?\n",
    "confids_list = sum_rank_df.confid.tolist()\n",
    "x = range(len(numeric_exp_df.columns))\n",
    "ranked_confs = sum_rank_df.sort_values(by=numeric_exp_df.columns[0]).confid.tolist()\n",
    "# from itertools import zip\n",
    "import numpy as np\n",
    "seen = [[] for _ in x]\n",
    "for ix in range(len(numeric_exp_df)):\n",
    "    y = numeric_exp_df.iloc[ix].values\n",
    "    axs.plot(\n",
    "        x,\n",
    "        y,\n",
    "        linewidth=3.1,\n",
    "#         marker=\".\",\n",
    "#         ms=18,\n",
    "        color=color_dict[sum_rank_df.confid.tolist()[ix]],\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    for x_, y_ in zip(x, y):\n",
    "        if np.isnan(y_):\n",
    "            continue\n",
    "            \n",
    "        if y_ in seen[x_]:\n",
    "            y_ -= 0.45\n",
    "        else: \n",
    "            seen[x_].append(y_)\n",
    "            \n",
    "        axs.text(\n",
    "            x_,\n",
    "            y_,\n",
    "            ranked_confs[ix],\n",
    "            fontsize=16,\n",
    "            horizontalalignment='center',\n",
    "#             verticalalignment='center'\n",
    "        )\n",
    "        \n",
    "axs.set_yticks(range(1, len(numeric_exp_df) + 1))\n",
    "# axs.set_yticklabels(ranked_confs)\n",
    "axs.set_yticklabels([])\n",
    "# axs.set_yticklabels(reversed(range(1, len(numeric_exp_df) + 1)), fontsize=12)\n",
    "axs.set_xticks(x)\n",
    "# axs.set_xticklabels([c[:5] for c in numeric_exp_df.columns], rotation=90)\n",
    "axs.set_xticklabels([c for c in numeric_exp_df.columns], fontsize=18, fontweight='bold')\n",
    "axs.set_xlim(0, len(numeric_exp_df.columns) - 1)\n",
    "axs.xaxis.tick_top()\n",
    "print(axs.get_facecolor())\n",
    "axs.annotate(\"\", xy=(1.05, 0), xytext=(1.05, 1),\n",
    "            arrowprops=dict(width=3, headwidth=8, headlength=8, color='grey'), xycoords='axes fraction')\n",
    "axs.annotate(\"best\\nrank\", xy=(1.054, 1), xytext=(1.054, 1), xycoords='axes fraction', fontsize=14, horizontalalignment='left', verticalalignment='top')\n",
    "axs.annotate(\"worst\\nrank\", xy=(1.054, 0), xytext=(1.054, 0), xycoords='axes fraction', fontsize=14, horizontalalignment='left', verticalalignment='bottom')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/Users/Paul/research/files/analysis/paper_plots/ranking.png\")\n",
    "plt.savefig(\"/home/tillb/Projects/failure-detection-benchmark/results/ranking.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAR PLOTS\n",
    "\n",
    "\n",
    "scale = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=scale * 0.35)\n",
    "for exp in [\"cifar100\"]:\n",
    "    cols = [c for c in rank_df.columns if c.startswith(exp + \"_\")]\n",
    "    cols = (\n",
    "        [\"{}_iid_study\".format(exp)]\n",
    "        + [c for c in cols if \"noise\" in c]\n",
    "        + [c for c in cols if \"in_class\" in c]\n",
    "        + [c for c in cols if \"proposed\" in c]\n",
    "    )\n",
    "    numeric_exp_df = dff[cols]\n",
    "    # todo DROPNAN?\n",
    "    confids_list = dff.confid.tolist()\n",
    "    x = range(len(numeric_exp_df.columns))\n",
    "    f, axs = plt.subplots(\n",
    "        nrows=1, ncols=len(cols), figsize=(scale * len(cols), scale * 2)\n",
    "    )\n",
    "\n",
    "    for ix, c in enumerate(cols):\n",
    "        sns.stripplot(ax=axs[ix], x=\"confid\", y=c, data=dff)\n",
    "        axs[ix].set_ylim(dff[c].min() - 4, dff[c].max() + 4)\n",
    "        axs[ix].set_xticklabels(axs[ix].get_xticklabels(), rotation=90)\n",
    "        title = axs[ix].get_ylabel()\n",
    "        title = title.replace(exp + \"_\", \"\")\n",
    "        title = title.replace(\"_proposed_mode\", \"\")\n",
    "        title = title.replace(\"_\", \"-\")\n",
    "        title = title.replace(\"-study-\", \"-shift-\")\n",
    "        title = title.replace(\"in-class\", \"sub-class\")\n",
    "        title = title.replace(\"-resize\", \"\")\n",
    "        axs[ix].set_title(title)\n",
    "        axs[ix].set_ylabel(\"\")\n",
    "        axs[ix].set_xlabel(\"\")\n",
    "    # plt.bar(x=\"x\", height=\"{}_iid_study\".format(exp), data=dff)\n",
    "    # for ix in range(len(numeric_exp_df)):\n",
    "    #     y = numeric_exp_df.iloc[ix].values\n",
    "    #     axs[ax_ix].plot(x, y)\n",
    "    # axs[ax_ix].set_yticks(range(1, len(numeric_exp_df) + 1))\n",
    "    # axs[ax_ix].set_yticklabels(rank_df[[\"confid\"] + [c for c in rank_df.columns if c.startswith(exp)]].sort_values(by=numeric_exp_df.columns[0]).confid.tolist())\n",
    "    # axs[ax_ix].set_xticks(x)\n",
    "    # axs[ax_ix].set_xticklabels([c for c in numeric_exp_df.columns], rotation = 90)\n",
    "    # axs[ax_ix].set_xlim(0, len(numeric_exp_df.columns) - 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OVERVOEW PLOTS\n",
    "\n",
    "metrics = [\"aurc\", \"accuracy\", \"failauc\"]\n",
    "plot_exps = [\"animals\"]  # exp_names\n",
    "cross_mode = False\n",
    "scale = 8\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=scale * 0.35)\n",
    "dims = [\"confid\"]\n",
    "\n",
    "# plot_df =\n",
    "\n",
    "for metric in metrics:\n",
    "    if not cross_mode:\n",
    "        for exp in plot_exps:\n",
    "            plot_data = df[df.study.str.startswith(exp + \"_\")][\n",
    "                [\"study\", \"confid\", \"run\", metric]\n",
    "            ]  # & (data[\"ne\"].str.contains(\"250\")) & (data[\"ap\"]==False)]\n",
    "            studies = plot_data.study.unique().tolist()\n",
    "            print(studies, plot_data.columns)\n",
    "            f, axs = plt.subplots(\n",
    "                nrows=len(dims),\n",
    "                ncols=len(studies),\n",
    "                figsize=(len(studies) * scale * 1.2, len(dims) * scale * 1.2),\n",
    "            )\n",
    "            for xix, dim in enumerate(dims):\n",
    "                for yix, study in enumerate(studies):\n",
    "                    y = metric\n",
    "                    sns.stripplot(\n",
    "                        ax=axs[yix],\n",
    "                        x=dim,\n",
    "                        y=metric,\n",
    "                        data=plot_data[plot_data.study == study],\n",
    "                        s=scale * 0.8,\n",
    "                    )\n",
    "                    sns.boxplot(\n",
    "                        ax=axs[yix],\n",
    "                        x=dim,\n",
    "                        y=metric,\n",
    "                        data=plot_data[plot_data.study == study],\n",
    "                        saturation=0,\n",
    "                        showbox=False,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=meanprops,\n",
    "                        meanline=True,\n",
    "                    )\n",
    "                    axs[yix].set_xticklabels(axs[yix].get_xticklabels(), rotation=90)\n",
    "\n",
    "                    # if \"iid\" in study and metric == \"aurc\":\n",
    "                    #     axs[xix, yix].set_ylim(4, 8)\n",
    "                    # if \"iid\" in study and metric == \"failauc\":\n",
    "                    #     axs[xix, yix].set_ylim(0.90, 0.96)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                \"/home/t974t/Projects/failure-detection-benchmark/results/paper_{}_{}.png\".format(\n",
    "                    exp, metric\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        # plot_data = df[df.study.str.startswith(exp)][[\"study\", \"confid\", \"run\", \"rew\", metric]] # & (data[\"ne\"].str.contains(\"250\")) & (data[\"ap\"]==False)]\n",
    "        plot_data = df[df.study.str.contains(\"iid_study\")][\n",
    "            [\"study\", \"confid\", \"run\", \"rew\", metric]\n",
    "        ]\n",
    "        print(studies, plot_data.columns)\n",
    "        f, axs = plt.subplots(\n",
    "            nrows=len(dims),\n",
    "            ncols=len(exp_names),\n",
    "            figsize=(len(exp_names) * scale, len(dims) * scale * 1.2),\n",
    "        )\n",
    "        for xix, dim in enumerate(dims):\n",
    "            for yix, exp in enumerate(exp_names):\n",
    "                y = metric\n",
    "                sns.stripplot(\n",
    "                    ax=axs[yix],\n",
    "                    x=dim,\n",
    "                    y=metric,\n",
    "                    data=plot_data[plot_data.study == \"{}_iid_study\".format(exp)],\n",
    "                    s=scale * 0.8,\n",
    "                )\n",
    "                sns.boxplot(\n",
    "                    ax=axs[yix],\n",
    "                    x=dim,\n",
    "                    y=metric,\n",
    "                    data=plot_data[plot_data.study == \"{}_iid_study\".format(exp)],\n",
    "                    saturation=0,\n",
    "                    showbox=False,\n",
    "                    showcaps=False,\n",
    "                    showfliers=False,\n",
    "                    whiskerprops=whiskerprops,\n",
    "                    showmeans=True,\n",
    "                    meanprops=meanprops,\n",
    "                    meanline=True,\n",
    "                )\n",
    "                axs[yix].set_xticklabels(axs[yix].get_xticklabels(), rotation=90)\n",
    "                axs[yix].set_xlabel(exp)\n",
    "                # if \"iid\" in study and metric == \"aurc\":\n",
    "                #     axs[xix, yix].set_ylim(4, 8)\n",
    "                # if \"iid\" in study and metric == \"failauc\":\n",
    "                #     axs[xix, yix].set_ylim(0.90, 0.96)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"/home/t974t/Projects/failure-detection-benchmark/results/paper_iid_{}.png\".format(\n",
    "                metric\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FINAL STRIP PLOTS\n",
    "def final_strip_plots():\n",
    "    metrics = [\n",
    "        \"accuracy\", \"aurc\", \"failauc\", \"ece\",  \"fail-NLL\"\n",
    "    ]\n",
    "    plot_exps = [\n",
    "        \"cifar10\",\n",
    "        \"cifar100\",\n",
    "        \"svhn\",\n",
    "        \"breeds\",\n",
    "        \"animals\",\n",
    "        \"camelyon\",\n",
    "    ]  # exp_names\n",
    "    cross_mode = False\n",
    "    scale = 15\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # sns.color_palette(\"tab20\")\n",
    "    # palette = sns.color_palette()\n",
    "    # c = []\n",
    "    # for ix in range(15):\n",
    "    #     print(ix)\n",
    "    #     c.append(palette[ix])\n",
    "    # print(c)\n",
    "    # random.shuffle(c)\n",
    "    # print(c)\n",
    "    sns.set_context(\"paper\", font_scale=scale * 0.35)\n",
    "    dims = [\"confid\"]\n",
    "\n",
    "    studies = [\n",
    "        'iid-study',\n",
    "        'sub-class-shift',\n",
    "        'corruption-shift-1',\n",
    "        'corruption-shift-2',\n",
    "        'corruption-shift-3',\n",
    "        'corruption-shift-4',\n",
    "        'corruption-shift-5',\n",
    "        'new-class-shift-cifar10',\n",
    "        'new-class-shift-cifar10-original-mode',\n",
    "        'new-class-shift-cifar100',\n",
    "        'new-class-shift-cifar100-original-mode',\n",
    "        'new-class-shift-svhn',\n",
    "        'new-class-shift-svhn-original-mode',\n",
    "        'new-class-shift-tinyimagenet',\n",
    "        'new-class-shift-tinyimagenet-original-mode'\n",
    "    ]\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    for exp in plot_exps:\n",
    "        print(f\"Creating plots for {exp}...\")\n",
    "        pdata = df[df.study.str.startswith(exp + \"_\")][\n",
    "            [\"study\", \"confid\", \"run\"] + metrics\n",
    "        ]\n",
    "\n",
    "        def fix_studies(n):\n",
    "            n = n.replace(exp + \"_\", \"\")\n",
    "            n = n.replace(\"_proposed_mode\", \"\")\n",
    "            n = n.replace(\"_\", \"-\")\n",
    "            n = n.replace(\"-study-\", \"-shift-\")\n",
    "            n = n.replace(\"in-class\", \"sub-class\")\n",
    "            n = n.replace(\"noise\", \"corruption\")\n",
    "            n = n.replace(\"-resize\", \"\")\n",
    "            n = n.replace(\"-wilds-ood-test\", \"\")\n",
    "            n = n.replace(\"-ood-test\", \"\")\n",
    "            n = n.replace(\"-superclasses\", \"\")\n",
    "            return n\n",
    "\n",
    "\n",
    "        plot_studies = pdata.study.unique().tolist()\n",
    "        plot_studies = [\n",
    "            c for c in plot_studies if not \"val_tuning\" in c\n",
    "        ]  # & (data[\"ne\"].str.contains(\"250\")) & (data[\"ap\"]==False)]\n",
    "        plot_studies = list(sorted(plot_studies, key=lambda x: fix_studies(x)))\n",
    "        # print(studies)\n",
    "        cols = [c for c in plot_studies if exp + \"_\" in c]\n",
    "        # plot_studies = studies\n",
    "        ncols = len(plot_studies)\n",
    "\n",
    "        nrows = len(metrics)\n",
    "        f, axs = plt.subplots(\n",
    "            nrows=nrows,\n",
    "            ncols=ncols,\n",
    "            figsize=(ncols * scale * 1.2, nrows * scale * 1.2),\n",
    "            squeeze=False\n",
    "        )\n",
    "        # axs = axs.flatten()\n",
    "\n",
    "        for mix, metric in enumerate(metrics):\n",
    "            plot_data = df[df.study.str.startswith(exp + \"_\")][\n",
    "                [\"study\", \"confid\", \"run\", metric]\n",
    "            ]\n",
    "            # print(plot_studies, plot_data.columns)\n",
    "            saxs = axs[mix]\n",
    "            for xix, dim in enumerate(dims):\n",
    "                skipped = 0\n",
    "                for yix, study in enumerate(studies):\n",
    "                    if study not in [fix_studies(s) for s in plot_studies]:\n",
    "                        skipped += 1\n",
    "                        continue\n",
    "\n",
    "                    yix = yix - skipped\n",
    "                    y = metric\n",
    "                    # print(plot_data.study.apply(fix_studies), study)\n",
    "                    data = plot_data[plot_data.study.apply(fix_studies) == study].sort_values(by=\"confid\")\n",
    "                    plot_colors = [\n",
    "                        color_dict[conf] for conf in data.confid.unique().tolist()\n",
    "                    ]\n",
    "                    # print(plot_colors)\n",
    "                    palette = sns.color_palette(plot_colors)\n",
    "                    # print(plot_colors)\n",
    "                    # print(data.confid.unique().tolist())\n",
    "                    sns.set_palette(palette)\n",
    "\n",
    "                    # print(data[~data[dim].str.startswith(\"VIT\")])\n",
    "\n",
    "                    # order = data[dim].str.replace(\"VIT-\", \"\").sort_values().unique()\n",
    "                    # data[dim] = data[dim].str.replace(\"VIT-\", \"\").sort_values().unique()\n",
    "\n",
    "                    # if not \"noise\" in study or \"noise_study_3\" in study:\n",
    "                    # print(study)\n",
    "                    sns.stripplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=dim,\n",
    "                        y=metric,\n",
    "                        data=data,\n",
    "                        s=scale * 1.6,\n",
    "                        label=dim,\n",
    "                        alpha=0.5\n",
    "                    )\n",
    "                    sns.boxplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=dim,\n",
    "                        y=metric,\n",
    "                        data=data,\n",
    "                        medianprops=dict(alpha=0),\n",
    "                        saturation=0,\n",
    "                        showbox=False,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=meanprops,\n",
    "                        meanline=True,\n",
    "                    )\n",
    "                    # axs[yix].set_xticklabels(\"\")\n",
    "                    saxs[yix].set_xticklabels(saxs[yix].get_xticklabels(), rotation=90)\n",
    "\n",
    "                    saxs[yix].set_title(fix_studies(study), pad=35)\n",
    "                    saxs[yix].set_ylabel(\"\")\n",
    "                    saxs[yix].set_xlabel(\"\")\n",
    "                    # lim = data[metric].mean() + data[metric].std()\n",
    "    #                 saxs[yix].set_ylim(data[metric].min(), data[metric].max())\n",
    "                    if yix == 0:\n",
    "                        saxs[yix].set_ylabel(metric)\n",
    "\n",
    "                    # if yix == 5:\n",
    "                    #     axs[yix].axis(\"off\")\n",
    "                    #     axs[yix-1].legend()\n",
    "\n",
    "                    # if \"iid\" in study and metric == \"aurc\":\n",
    "                    #     axs[xix, yix].set_ylim(4, 8)\n",
    "                    # if \"iid\" in study and metric == \"failauc\":\n",
    "                    #     axs[xix, yix].set_ylim(0.90, 0.96)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"/home/tillb/Projects/failure-detection-benchmark/results/final_paper_{}.png\".format(\n",
    "                exp\n",
    "            )\n",
    "        )\n",
    "        plt.close(f)\n",
    "        \n",
    "final_strip_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FINAL STRIP PLOTS\n",
    "\n",
    "def final_strip_plots_sc():\n",
    "    metrics = [\n",
    "        \"accuracy\", \"aurc\", \"failauc\", \"ece\",  \"fail-NLL\"\n",
    "    ]\n",
    "    plot_exps = [\n",
    "        \"cifar10\",\n",
    "        \"cifar100\",\n",
    "        \"svhn\",\n",
    "        \"breeds\",\n",
    "        \"animals\",\n",
    "        \"camelyon\",\n",
    "    ]  # exp_names\n",
    "    cross_mode = False\n",
    "    scale = 15\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # sns.color_palette(\"tab20\")\n",
    "    # palette = sns.color_palette()\n",
    "    # c = []\n",
    "    # for ix in range(15):\n",
    "    #     print(ix)\n",
    "    #     c.append(palette[ix])\n",
    "    # print(c)\n",
    "    # random.shuffle(c)\n",
    "    # print(c)\n",
    "    sns.set_context(\"paper\", font_scale=scale * 0.35)\n",
    "    dims = [\"confid\"]\n",
    "\n",
    "    studies = [\n",
    "        'iid-study',\n",
    "        'sub-class-shift',\n",
    "        'corruption-shift-1',\n",
    "        'corruption-shift-2',\n",
    "        'corruption-shift-3',\n",
    "        'corruption-shift-4',\n",
    "        'corruption-shift-5',\n",
    "        'new-class-shift-cifar10',\n",
    "        'new-class-shift-cifar10-original-mode',\n",
    "        'new-class-shift-cifar100',\n",
    "        'new-class-shift-cifar100-original-mode',\n",
    "        'new-class-shift-svhn',\n",
    "        'new-class-shift-svhn-original-mode',\n",
    "        'new-class-shift-tinyimagenet',\n",
    "        'new-class-shift-tinyimagenet-original-mode'\n",
    "    ]\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    for exp in plot_exps:\n",
    "        print(f\"Creating plots for {exp}...\")\n",
    "        pdata = df[df.study.str.startswith(exp + \"_\")][\n",
    "            [\"study\", \"confid\", \"run\"] + metrics\n",
    "        ]\n",
    "\n",
    "        def fix_studies(n):\n",
    "            n = n.replace(exp + \"_\", \"\")\n",
    "            n = n.replace(\"_proposed_mode\", \"\")\n",
    "            n = n.replace(\"_\", \"-\")\n",
    "            n = n.replace(\"-study-\", \"-shift-\")\n",
    "            n = n.replace(\"in-class\", \"sub-class\")\n",
    "            n = n.replace(\"noise\", \"corruption\")\n",
    "            n = n.replace(\"-resize\", \"\")\n",
    "            n = n.replace(\"-wilds-ood-test\", \"\")\n",
    "            n = n.replace(\"-ood-test\", \"\")\n",
    "            n = n.replace(\"-superclasses\", \"\")\n",
    "            return n\n",
    "\n",
    "\n",
    "        plot_studies = pdata.study.unique().tolist()\n",
    "        plot_studies = [\n",
    "            c for c in plot_studies if not \"val_tuning\" in c\n",
    "        ]  # & (data[\"ne\"].str.contains(\"250\")) & (data[\"ap\"]==False)]\n",
    "        plot_studies = list(sorted(plot_studies, key=lambda x: fix_studies(x)))\n",
    "        # print(studies)\n",
    "        cols = [c for c in plot_studies if exp + \"_\" in c]\n",
    "        # plot_studies = studies\n",
    "        ncols = len(plot_studies)\n",
    "\n",
    "        nrows = len(metrics)\n",
    "        f, axs = plt.subplots(\n",
    "            nrows=nrows,\n",
    "            ncols=ncols,\n",
    "            figsize=(ncols * scale * 1.2, nrows * scale * 1.2),\n",
    "            squeeze=False\n",
    "        )\n",
    "        # axs = axs.flatten()\n",
    "\n",
    "        for mix, metric in enumerate(metrics):\n",
    "            plot_data = df[df.study.str.startswith(exp + \"_\")][\n",
    "                [\"study\", \"confid\", \"run\", metric]\n",
    "            ]\n",
    "            # print(plot_studies, plot_data.columns)\n",
    "            saxs = axs[mix]\n",
    "            for xix, dim in enumerate(dims):\n",
    "                skipped = 0\n",
    "                for yix, study in enumerate(studies):\n",
    "                    if study not in [fix_studies(s) for s in plot_studies]:\n",
    "                        skipped += 1\n",
    "                        continue\n",
    "\n",
    "                    yix = yix - skipped\n",
    "                    y = metric\n",
    "                    # print(plot_data.study.apply(fix_studies), study)\n",
    "                    data = plot_data[plot_data.study.apply(fix_studies) == study].sort_values(by=\"confid\")\n",
    "                    plot_colors = [\n",
    "                        color_dict[conf] for conf in data.confid.unique().tolist()\n",
    "                    ]\n",
    "                    # print(plot_colors)\n",
    "                    palette = sns.color_palette(plot_colors)\n",
    "                    # print(plot_colors)\n",
    "                    # print(data.confid.unique().tolist())\n",
    "                    sns.set_palette(palette)\n",
    "\n",
    "                    # print(data[~data[dim].str.startswith(\"VIT\")])\n",
    "\n",
    "                    order = data[dim].str.replace(\"VIT-\", \"\").sort_values().unique()\n",
    "\n",
    "                    # if not \"noise\" in study or \"noise_study_3\" in study:\n",
    "                    # print(study)\n",
    "                    sns.stripplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=data[~data[dim].str.startswith(\"VIT\")][dim],\n",
    "                        y=metric,\n",
    "                        data=data[~data[dim].str.startswith(\"VIT\")],\n",
    "                        s=scale * 1.6,\n",
    "                        label=dim,\n",
    "                        alpha=0.5,\n",
    "                        order=order,\n",
    "                    )\n",
    "                    sns.stripplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=data[data[dim].str.startswith(\"VIT\")][dim].str.replace(\"VIT-\", \"\"),\n",
    "                        y=metric,\n",
    "                        data=data[data[dim].str.startswith(\"VIT\")],\n",
    "                        s=scale * 1.6,\n",
    "                        label=dim,\n",
    "                        marker='X',\n",
    "                        alpha=0.5,\n",
    "                        order=order,\n",
    "                    )\n",
    "                    sns.boxplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=data[~data[dim].str.startswith(\"VIT\")][dim],\n",
    "                        y=metric,\n",
    "                        data=data[~data[dim].str.startswith(\"VIT\")],\n",
    "                        medianprops=dict(alpha=0),\n",
    "                        saturation=0,\n",
    "                        showbox=False,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=meanprops,\n",
    "                        meanline=True,\n",
    "                        order=order,\n",
    "                    )\n",
    "                    sns.boxplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=data[data[dim].str.startswith(\"VIT-\")][dim].str.replace(\"VIT-\", \"\"),\n",
    "                        y=metric,\n",
    "                        data=data[data[dim].str.startswith(\"VIT-\")],\n",
    "                        medianprops=dict(alpha=0),\n",
    "                        saturation=0,\n",
    "                        showbox=False,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=dict(linewidth=6, alpha=1, zorder=99, dashes=(1,1,1,1,1,1,1)),\n",
    "                        meanline=True,\n",
    "                        order=order,\n",
    "                    )\n",
    "                    # axs[yix].set_xticklabels(\"\")\n",
    "                    saxs[yix].set_xticklabels(saxs[yix].get_xticklabels(), rotation=90)\n",
    "\n",
    "                    saxs[yix].set_title(fix_studies(study), pad=35)\n",
    "                    saxs[yix].set_ylabel(\"\")\n",
    "                    saxs[yix].set_xlabel(\"\")\n",
    "                    # lim = data[metric].mean() + data[metric].std()\n",
    "    #                 saxs[yix].set_ylim(data[metric].min(), data[metric].max())\n",
    "                    if yix == 0:\n",
    "                        saxs[yix].set_ylabel(metric)\n",
    "\n",
    "                    # if yix == 5:\n",
    "                    #     axs[yix].axis(\"off\")\n",
    "                    #     axs[yix-1].legend()\n",
    "\n",
    "                    # if \"iid\" in study and metric == \"aurc\":\n",
    "                    #     axs[xix, yix].set_ylim(4, 8)\n",
    "                    # if \"iid\" in study and metric == \"failauc\":\n",
    "                    #     axs[xix, yix].set_ylim(0.90, 0.96)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"/home/tillb/Projects/failure-detection-benchmark/results/final_paper_{}_single_column.png\".format(\n",
    "                exp\n",
    "            )\n",
    "        )\n",
    "        plt.close(f)\n",
    "        \n",
    "final_strip_plots_sc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FINAL STRIP PLOTS\n",
    "\n",
    "def final_strip_plots_box():\n",
    "    metrics = [\n",
    "        \"accuracy\", \"aurc\", \"failauc\", \"ece\",  \"fail-NLL\"\n",
    "    ]\n",
    "    plot_exps = [\n",
    "        \"cifar10\",\n",
    "        \"cifar100\",\n",
    "        \"svhn\",\n",
    "        \"breeds\",\n",
    "        \"animals\",\n",
    "        \"camelyon\",\n",
    "    ]  # exp_names\n",
    "    cross_mode = False\n",
    "    scale = 15\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    # sns.color_palette(\"tab20\")\n",
    "    # palette = sns.color_palette()\n",
    "    # c = []\n",
    "    # for ix in range(15):\n",
    "    #     print(ix)\n",
    "    #     c.append(palette[ix])\n",
    "    # print(c)\n",
    "    # random.shuffle(c)\n",
    "    # print(c)\n",
    "    sns.set_context(\"paper\", font_scale=scale * 0.35)\n",
    "    dims = [\"confid\"]\n",
    "\n",
    "    studies = [\n",
    "        'iid-study',\n",
    "        'sub-class-shift',\n",
    "        'corruption-shift-1',\n",
    "        'corruption-shift-2',\n",
    "        'corruption-shift-3',\n",
    "        'corruption-shift-4',\n",
    "        'corruption-shift-5',\n",
    "        'new-class-shift-cifar10',\n",
    "        'new-class-shift-cifar10-original-mode',\n",
    "        'new-class-shift-cifar100',\n",
    "        'new-class-shift-cifar100-original-mode',\n",
    "        'new-class-shift-svhn',\n",
    "        'new-class-shift-svhn-original-mode',\n",
    "        'new-class-shift-tinyimagenet',\n",
    "        'new-class-shift-tinyimagenet-original-mode'\n",
    "    ]\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    for exp in plot_exps:\n",
    "        print(f\"Creating plots for {exp}...\")\n",
    "        pdata = df[df.study.str.startswith(exp + \"_\")][\n",
    "            [\"study\", \"confid\", \"run\"] + metrics\n",
    "        ]\n",
    "\n",
    "        def fix_studies(n):\n",
    "            n = n.replace(exp + \"_\", \"\")\n",
    "            n = n.replace(\"_proposed_mode\", \"\")\n",
    "            n = n.replace(\"_\", \"-\")\n",
    "            n = n.replace(\"-study-\", \"-shift-\")\n",
    "            n = n.replace(\"in-class\", \"sub-class\")\n",
    "            n = n.replace(\"noise\", \"corruption\")\n",
    "            n = n.replace(\"-resize\", \"\")\n",
    "            n = n.replace(\"-wilds-ood-test\", \"\")\n",
    "            n = n.replace(\"-ood-test\", \"\")\n",
    "            n = n.replace(\"-superclasses\", \"\")\n",
    "            return n\n",
    "\n",
    "\n",
    "        plot_studies = pdata.study.unique().tolist()\n",
    "        plot_studies = [\n",
    "            c for c in plot_studies if not \"val_tuning\" in c\n",
    "        ]  # & (data[\"ne\"].str.contains(\"250\")) & (data[\"ap\"]==False)]\n",
    "        plot_studies = list(sorted(plot_studies, key=lambda x: fix_studies(x)))\n",
    "        # print(studies)\n",
    "        cols = [c for c in plot_studies if exp + \"_\" in c]\n",
    "        # plot_studies = studies\n",
    "        ncols = len(plot_studies)\n",
    "\n",
    "        nrows = len(metrics)\n",
    "        f, axs = plt.subplots(\n",
    "            nrows=nrows,\n",
    "            ncols=ncols,\n",
    "            figsize=(ncols * scale * 1.2, nrows * scale * 1.2),\n",
    "            squeeze=False\n",
    "        )\n",
    "        # axs = axs.flatten()\n",
    "\n",
    "        for mix, metric in enumerate(metrics):\n",
    "            plot_data = df[df.study.str.startswith(exp + \"_\")][\n",
    "                [\"study\", \"confid\", \"run\", metric]\n",
    "            ]\n",
    "            # print(plot_studies, plot_data.columns)\n",
    "            saxs = axs[mix]\n",
    "            for xix, dim in enumerate(dims):\n",
    "                skipped = 0\n",
    "                for yix, study in enumerate(studies):\n",
    "                    if study not in [fix_studies(s) for s in plot_studies]:\n",
    "                        skipped += 1\n",
    "                        continue\n",
    "\n",
    "                    yix = yix - skipped\n",
    "                    y = metric\n",
    "                    # print(plot_data.study.apply(fix_studies), study)\n",
    "                    data = plot_data[plot_data.study.apply(fix_studies) == study].sort_values(by=\"confid\")\n",
    "                    plot_colors = [\n",
    "                        color_dict[conf] for conf in data.confid.unique().tolist()\n",
    "                    ]\n",
    "                    # print(plot_colors)\n",
    "                    palette = sns.color_palette(plot_colors)\n",
    "                    # print(plot_colors)\n",
    "                    # print(data.confid.unique().tolist())\n",
    "                    sns.set_palette(palette)\n",
    "\n",
    "                    # print(data[~data[dim].str.startswith(\"VIT\")])\n",
    "\n",
    "                    order = data[dim].str.replace(\"VIT-\", \"\").sort_values().unique()\n",
    "\n",
    "                    # if not \"noise\" in study or \"noise_study_3\" in study:\n",
    "                    # print(study)\n",
    "                    # sns.stripplot(\n",
    "                    #     ax=saxs[yix],\n",
    "                    #     x=data[~data[dim].str.startswith(\"VIT\")][dim],\n",
    "                    #     y=metric,\n",
    "                    #     data=data[~data[dim].str.startswith(\"VIT\")],\n",
    "                    #     s=scale * 1.6,\n",
    "                    #     label=dim,\n",
    "                    #     order=order,\n",
    "                    # )\n",
    "                    # sns.stripplot(\n",
    "                    #     ax=saxs[yix],\n",
    "                    #     x=data[data[dim].str.startswith(\"VIT\")][dim].str.replace(\"VIT-\", \"\"),\n",
    "                    #     y=metric,\n",
    "                    #     data=data[data[dim].str.startswith(\"VIT\")],\n",
    "                    #     s=scale * 1.6,\n",
    "                    #     label=dim,\n",
    "                    #     marker='X',\n",
    "                    #     order=order,\n",
    "                    # )\n",
    "                    sns.boxplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=data[~data[dim].str.startswith(\"VIT\")][dim],\n",
    "                        y=metric,\n",
    "                        data=data[~data[dim].str.startswith(\"VIT\")],\n",
    "                        medianprops=dict(alpha=0),\n",
    "                        saturation=0,\n",
    "                        showbox=True,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=meanprops,\n",
    "                        meanline=True,\n",
    "                        order=order,\n",
    "                    )\n",
    "                    sns.boxplot(\n",
    "                        ax=saxs[yix],\n",
    "                        x=data[data[dim].str.startswith(\"VIT-\")][dim].str.replace(\"VIT-\", \"\"),\n",
    "                        y=metric,\n",
    "                        data=data[data[dim].str.startswith(\"VIT-\")],\n",
    "                        medianprops=dict(alpha=0),\n",
    "                        saturation=0,\n",
    "                        showbox=True,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=meanprops,\n",
    "                        meanline=True,\n",
    "                        order=order,\n",
    "                    )\n",
    "                    # axs[yix].set_xticklabels(\"\")\n",
    "                    saxs[yix].set_xticklabels(saxs[yix].get_xticklabels(), rotation=90)\n",
    "\n",
    "                    saxs[yix].set_title(fix_studies(study), pad=35)\n",
    "                    saxs[yix].set_ylabel(\"\")\n",
    "                    saxs[yix].set_xlabel(\"\")\n",
    "                    # lim = data[metric].mean() + data[metric].std()\n",
    "    #                 saxs[yix].set_ylim(data[metric].min(), data[metric].max())\n",
    "                    if yix == 0:\n",
    "                        saxs[yix].set_ylabel(metric)\n",
    "\n",
    "                    # if yix == 5:\n",
    "                    #     axs[yix].axis(\"off\")\n",
    "                    #     axs[yix-1].legend()\n",
    "\n",
    "                    # if \"iid\" in study and metric == \"aurc\":\n",
    "                    #     axs[xix, yix].set_ylim(4, 8)\n",
    "                    # if \"iid\" in study and metric == \"failauc\":\n",
    "                    #     axs[xix, yix].set_ylim(0.90, 0.96)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            \"/home/tillb/Projects/failure-detection-benchmark/results/final_paper_{}_single_column_box.png\".format(\n",
    "                exp\n",
    "            )\n",
    "        )\n",
    "        plt.close(f)\n",
    "        \n",
    "final_strip_plots_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ************************ RISK PLOTS *******************************\n",
    "import random\n",
    "\n",
    "metrics = [\"ece\"]\n",
    "plot_exps = [\"cifar100\"]  # exp_names\n",
    "cross_mode = False\n",
    "scale = 15\n",
    "sns.set_style(\"whitegrid\")\n",
    "# sns.color_palette(\"tab20\")\n",
    "# palette = sns.color_palette()\n",
    "# c = []\n",
    "# for ix in range(15):\n",
    "#     print(ix)\n",
    "#     c.append(palette[ix])\n",
    "# print(c)\n",
    "# random.shuffle(c)\n",
    "# print(c)\n",
    "# sns.set_palette(c)\n",
    "sns.set_context(\"paper\", font_scale=scale * 0.5)\n",
    "dims = [\"confid\"]\n",
    "\n",
    "\n",
    "for metric in metrics:\n",
    "    if not cross_mode:\n",
    "        for exp in plot_exps:\n",
    "            plot_data = df[df.study.str.startswith(exp + \"_\")][\n",
    "                [\"study\", \"confid\", \"run\", metric]\n",
    "            ]\n",
    "            studies = plot_data.study.unique().tolist()\n",
    "            studies = [\n",
    "                c for c in studies if not \"val_tuning\" in c\n",
    "            ]  # & (data[\"ne\"].str.contains(\"250\")) & (data[\"ap\"]==False)]\n",
    "            plot_studies = studies  # [c for c in studies if not (\"noise\" in c or \"noise_study_1\" in c)]\n",
    "            cols = [c for c in plot_studies if exp + \"_\" in c]\n",
    "            plot_studies = (\n",
    "                [\"{}_iid_study\".format(exp)]\n",
    "                + [c for c in cols if \"noise\" in c]\n",
    "                + [c for c in cols if \"in_class\" in c]\n",
    "                + [c for c in cols if \"proposed\" in c]\n",
    "            )\n",
    "            # plot_studies = [c for c in cols if \"noise\" in c]\n",
    "            print(studies, plot_data.columns)\n",
    "            ncols = len(plot_studies)\n",
    "            print(\"CHECK COLS\", ncols, plot_studies)\n",
    "            f, axs = plt.subplots(\n",
    "                nrows=len(dims),\n",
    "                ncols=ncols,\n",
    "                figsize=(6 * scale * 1.2, len(dims) * scale * 1.2),\n",
    "            )\n",
    "            for xix, dim in enumerate(dims):\n",
    "                for yix, study in enumerate(plot_studies):\n",
    "                    y = metric\n",
    "                    data = plot_data[plot_data.study == study].sort_values(by=\"confid\")\n",
    "                    # if not \"noise\" in study or \"noise_study_3\" in study:\n",
    "                    print(study)\n",
    "                    sns.stripplot(\n",
    "                        ax=axs[yix],\n",
    "                        x=dim,\n",
    "                        y=metric,\n",
    "                        data=data,\n",
    "                        s=scale * 1.6,\n",
    "                        label=dim,\n",
    "                    )\n",
    "                    sns.boxplot(\n",
    "                        ax=axs[yix],\n",
    "                        x=dim,\n",
    "                        y=metric,\n",
    "                        data=data,\n",
    "                        medianprops=dict(alpha=0),\n",
    "                        saturation=0,\n",
    "                        showbox=False,\n",
    "                        showcaps=False,\n",
    "                        showfliers=False,\n",
    "                        whiskerprops=whiskerprops,\n",
    "                        showmeans=True,\n",
    "                        meanprops=meanprops,\n",
    "                        meanline=True,\n",
    "                    )\n",
    "                    # axs[yix].set_xticklabels(\"\")\n",
    "                    axs[yix].set_xticklabels(axs[yix].get_xticklabels(), rotation=90)\n",
    "                    title = study\n",
    "                    title = title.replace(exp + \"_\", \"\")\n",
    "                    title = title.replace(\"_proposed_mode\", \"\")\n",
    "                    title = title.replace(\"_\", \"-\")\n",
    "                    title = title.replace(\"-study-\", \"-shift-\")\n",
    "                    title = title.replace(\"in-class\", \"sub-class\")\n",
    "                    title = title.replace(\"noise\", \"corruption\")\n",
    "                    title = title.replace(\"-resize\", \"\")\n",
    "                    title = title.replace(\"-wilds-ood-test\", \"\")\n",
    "                    title = title.replace(\"-ood-test\", \"\")\n",
    "                    title = title.replace(\"-superclasses\", \"\")\n",
    "                    axs[yix].set_title(title, pad=35)\n",
    "                    axs[yix].set_ylabel(\"\")\n",
    "                    axs[yix].set_xlabel(\"\")\n",
    "                    lim = data[metric].mean() + data[metric].std()\n",
    "                    axs[yix].set_ylim(axs[yix].get_ylim()[0], lim)\n",
    "                    if yix == 0:\n",
    "                        axs[yix].set_ylabel(exp)\n",
    "\n",
    "                    # if yix == 5:\n",
    "                    #     axs[yix].axis(\"off\")\n",
    "                    #     axs[yix-1].legend()\n",
    "\n",
    "                    # if \"iid\" in study and metric == \"aurc\":\n",
    "                    #     axs[xix, yix].set_ylim(4, 8)\n",
    "                    # if \"iid\" in study and metric == \"failauc\":\n",
    "                    #     axs[xix, yix].set_ylim(0.90, 0.96)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                \"/home/t974t/Projects/failure-detection-benchmark/results/RISK_final_paper_{}_{}.png\".format(\n",
    "                    exp, metric\n",
    "                )\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
